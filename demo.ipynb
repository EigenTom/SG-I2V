{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa238e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lee_li/miniconda3/envs/t2v/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lee_li/miniconda3/envs/t2v/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> model checkpoint loaded.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from lvdm.models.samplers.ddim import DDIMSampler\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(42)\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from einops import rearrange\n",
    "from pytorch_lightning import seed_everything\n",
    "from scripts.evaluation.initializer import *\n",
    "from utils.utils import instantiate_from_config\n",
    "from scripts.evaluation.funcs import load_model_checkpoint, load_prompts, load_image_batch, get_filelist, save_videos\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "ckpt_path = \"/home/lee_li/axton_workspace/t2v_newbet/SG-I2V/checkpoints/base_512_v2/model.ckpt\"\n",
    "config = \"/home/lee_li/axton_workspace/t2v_newbet/SG-I2V/configs/inference_t2v_512_v2.0.yaml\"\n",
    "config = OmegaConf.load(config)\n",
    "model_config = config.pop(\"model\", OmegaConf.create())\n",
    "model = instantiate_from_config(model_config)\n",
    "model = model.to(device)\n",
    "model = load_model_checkpoint(model, ckpt_path)\n",
    "model.eval()\n",
    "sampler = DDIMSampler(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f9c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_downsample_blocks(model, pattern=\"input_blocks\", verbose=True):\n",
    "    hooks = []\n",
    "\n",
    "    def hook_fn(name):\n",
    "        def fn(module, input, output):\n",
    "            in_shapes = [i.shape if isinstance(i, torch.Tensor) else type(i) for i in input]\n",
    "            if isinstance(output, torch.Tensor):\n",
    "                out_shape = output.shape\n",
    "            elif isinstance(output, (list, tuple)):\n",
    "                out_shape = [o.shape if isinstance(o, torch.Tensor) else type(o) for o in output]\n",
    "            else:\n",
    "                out_shape = type(output)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"[{name}] Input: {in_shapes} → Output: {out_shape}\")\n",
    "        return fn\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if pattern in name: # and name.endswith(\".0\"):\n",
    "            hooks.append(module.register_forward_hook(hook_fn(name)))\n",
    "    \n",
    "    return hooks\n",
    "\n",
    "# hooks = hook_downsample_blocks(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f21641bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print out model's all layers\n",
    "# for name, module in model.named_modules():\n",
    "#     print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65e6432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDIM scale True\n",
      "[DEBUG]Conditioning textual context shape: torch.Size([1, 77, 1024])\n",
      "[DEBUG] sim shape: torch.Size([80, 2560, 77])\n",
      "[DEBUG] attn shape: torch.Size([80, 2560, 77])\n",
      "[DEBUG] Height: 40, Width: 64\n",
      "[DEBUG] sim shape: torch.Size([80, 2560, 77])\n",
      "[DEBUG] attn shape: torch.Size([80, 2560, 77])\n",
      "[DEBUG] Height: 40, Width: 64\n",
      "[DEBUG] sim shape: torch.Size([160, 640, 77])\n",
      "[DEBUG] attn shape: torch.Size([160, 640, 77])\n",
      "[DEBUG] Height: 20, Width: 32\n",
      "[DEBUG] sim shape: torch.Size([160, 640, 77])\n",
      "[DEBUG] attn shape: torch.Size([160, 640, 77])\n",
      "[DEBUG] Height: 20, Width: 32\n",
      "[DEBUG] sim shape: torch.Size([320, 160, 77])\n",
      "[DEBUG] attn shape: torch.Size([320, 160, 77])\n",
      "[DEBUG] Height: 10, Width: 16\n",
      "[DEBUG] sim shape: torch.Size([320, 160, 77])\n",
      "[DEBUG] attn shape: torch.Size([320, 160, 77])\n",
      "[DEBUG] Height: 10, Width: 16\n",
      "[DEBUG] sim shape: torch.Size([320, 40, 77])\n",
      "[DEBUG] attn shape: torch.Size([320, 40, 77])\n",
      "[DEBUG] Height: 5, Width: 8\n",
      "[DEBUG] sim shape: torch.Size([320, 160, 77])\n",
      "[DEBUG] attn shape: torch.Size([320, 160, 77])\n",
      "[DEBUG] Height: 10, Width: 16\n",
      "[DEBUG] sim shape: torch.Size([320, 160, 77])\n",
      "[DEBUG] attn shape: torch.Size([320, 160, 77])\n",
      "[DEBUG] Height: 10, Width: 16\n",
      "[DEBUG] sim shape: torch.Size([320, 160, 77])\n",
      "[DEBUG] attn shape: torch.Size([320, 160, 77])\n",
      "[DEBUG] Height: 10, Width: 16\n",
      "[DEBUG] sim shape: torch.Size([160, 640, 77])\n",
      "[DEBUG] attn shape: torch.Size([160, 640, 77])\n",
      "[DEBUG] Height: 20, Width: 32\n",
      "[DEBUG] sim shape: torch.Size([160, 640, 77])\n",
      "[DEBUG] attn shape: torch.Size([160, 640, 77])\n",
      "[DEBUG] Height: 20, Width: 32\n",
      "[DEBUG] sim shape: torch.Size([160, 640, 77])\n",
      "[DEBUG] attn shape: torch.Size([160, 640, 77])\n",
      "[DEBUG] Height: 20, Width: 32\n",
      "[DEBUG] sim shape: torch.Size([80, 2560, 77])\n",
      "[DEBUG] attn shape: torch.Size([80, 2560, 77])\n",
      "[DEBUG] Height: 40, Width: 64\n",
      "[DEBUG] sim shape: torch.Size([80, 2560, 77])\n",
      "[DEBUG] attn shape: torch.Size([80, 2560, 77])\n",
      "[DEBUG] Height: 40, Width: 64\n",
      "[DEBUG] sim shape: torch.Size([80, 2560, 77])\n",
      "[DEBUG] attn shape: torch.Size([80, 2560, 77])\n",
      "[DEBUG] Height: 40, Width: 64\n",
      "[INFO][get_attention_] Completed Attn Map Extraction.\n"
     ]
    }
   ],
   "source": [
    "agent = initializer(model, sampler)\n",
    "\n",
    "# prompt = [[\"A squirrel jumping from one tree to another.\"]]\n",
    "prompt = [[\"cat\"]]\n",
    "\n",
    "latent_shape = [1, 4, 16, 40, 64]\n",
    "\n",
    "img = torch.randn(latent_shape).to(device)\n",
    "\n",
    "attn_maps = agent.get_attn(prompt, img, scale=1.0, steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ede23b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49406, 320, 14004, 11476, 633, 637, 2677, 531, 1380, 269, 49407]\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPTokenizer\n",
    "\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "text = prompt[0][0]\n",
    "token_ids = tokenizer.encode(text)  # returns [49406, ..., 49407]\n",
    "print(token_ids)\n",
    "\n",
    "# A squirrel jumping from one tree to another.\n",
    "\n",
    "# 第一个是 [CLS]（id=49406）\n",
    "# 最后是 [EOS]（id=49407）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e6e0dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 16])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_maps[0].shape\n",
    "\n",
    "tmp_attn_map = attn_maps[0][0]\n",
    "\n",
    "# should be the first frame\n",
    "tmp_attn_map.shape\n",
    "\n",
    "# then get the 3rd token, \"squirrel\"'s attention heatmap on this frame (0th frame)\n",
    "token_idx = 2\n",
    "\n",
    "# get the 3rd tensor from the [10, 16, 40] tensor\n",
    "this_attn_map = tmp_attn_map[:,:,token_idx]\n",
    "print(this_attn_map.shape)\n",
    "\n",
    "# try to visualize the attention map\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(this_attn_map)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c29fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the attn map over the 3rd dimension\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t2v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
