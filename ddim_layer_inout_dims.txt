DDIM scale True
[DEBUG]Conditioning textual context shape: torch.Size([1, 77, 1024])
[diffusion_model.input_blocks.0.0] Input: [torch.Size([16, 4, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.0] Input: [torch.Size([16, 4, 40, 64]), torch.Size([16, 1280])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.1.0.in_layers.0] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.1.0.in_layers.1] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.1.0.in_layers.2] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.1.0.in_layers] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.1.0.emb_layers.0] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.1.0.emb_layers.1] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 320])
[diffusion_model.input_blocks.1.0.emb_layers] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 320])
[diffusion_model.input_blocks.1.0.out_layers.0] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.1.0.out_layers.1] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.1.0.out_layers.2] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.1.0.out_layers.3] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.1.0.out_layers] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.1.0.skip_connection] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv1.0] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv1.1] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv1.2] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv1] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv2.0] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv2.1] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv2.2] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv2.3] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv2] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv3.0] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv3.1] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv3.2] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv3.3] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv3] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv4.0] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv4.1] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv4.2] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv4.3] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv.conv4] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0.temopral_conv] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.0] Input: [torch.Size([16, 320, 40, 64]), torch.Size([16, 1280]), <class 'int'>] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.1.1.norm] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.1.1.proj_in] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.1] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k] Input: [torch.Size([16, 77, 1024])] → Output: torch.Size([16, 77, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v] Input: [torch.Size([16, 77, 1024])] → Output: torch.Size([16, 77, 320])
[DEBUG] Height: 40, Width: 64
[diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.1] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 2560])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 1280])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.1] Input: [torch.Size([16, 2560, 1280])] → Output: torch.Size([16, 2560, 1280])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2] Input: [torch.Size([16, 2560, 1280])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0.ff] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.transformer_blocks.0] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1.proj_out] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.1.1] Input: [torch.Size([16, 320, 40, 64]), torch.Size([16, 77, 1024])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.1.2.norm] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1.2.proj_in] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.norm1] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.attn1.to_q] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.attn1.to_k] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.attn1.to_v] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.attn1.to_out.0] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.attn1.to_out.1] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.attn1.to_out] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.attn1] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.norm2] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.attn2.to_q] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.attn2.to_k] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.attn2.to_v] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.attn2.to_out.0] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.attn2.to_out.1] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.attn2.to_out] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.attn2] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.norm3] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.ff.net.0.proj] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 2560])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.ff.net.0] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 1280])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.ff.net.1] Input: [torch.Size([2560, 16, 1280])] → Output: torch.Size([2560, 16, 1280])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.ff.net.2] Input: [torch.Size([2560, 16, 1280])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.ff.net] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0.ff] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.transformer_blocks.0] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.1.2.proj_out] Input: [torch.Size([1, 2560, 16, 320])] → Output: torch.Size([1, 2560, 16, 320])
[diffusion_model.input_blocks.1.2] Input: [torch.Size([1, 320, 16, 40, 64]), torch.Size([16, 77, 1024])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.1] Input: [torch.Size([16, 320, 40, 64]), torch.Size([16, 1280])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.2.0.in_layers.0] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.2.0.in_layers.1] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.2.0.in_layers.2] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.2.0.in_layers] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.2.0.emb_layers.0] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.2.0.emb_layers.1] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 320])
[diffusion_model.input_blocks.2.0.emb_layers] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 320])
[diffusion_model.input_blocks.2.0.out_layers.0] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.2.0.out_layers.1] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.2.0.out_layers.2] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.2.0.out_layers.3] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.2.0.out_layers] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.2.0.skip_connection] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv1.0] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv1.1] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv1.2] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv1] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv2.0] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv2.1] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv2.2] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv2.3] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv2] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv3.0] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv3.1] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv3.2] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv3.3] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv3] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv4.0] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv4.1] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv4.2] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv4.3] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv.conv4] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0.temopral_conv] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.0] Input: [torch.Size([16, 320, 40, 64]), torch.Size([16, 1280]), <class 'int'>] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.2.1.norm] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.2.1.proj_in] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.1] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k] Input: [torch.Size([16, 77, 1024])] → Output: torch.Size([16, 77, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v] Input: [torch.Size([16, 77, 1024])] → Output: torch.Size([16, 77, 320])
[DEBUG] Height: 40, Width: 64
[diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.1] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 2560])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 1280])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.1] Input: [torch.Size([16, 2560, 1280])] → Output: torch.Size([16, 2560, 1280])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2] Input: [torch.Size([16, 2560, 1280])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0.ff] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.transformer_blocks.0] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1.proj_out] Input: [torch.Size([16, 2560, 320])] → Output: torch.Size([16, 2560, 320])
[diffusion_model.input_blocks.2.1] Input: [torch.Size([16, 320, 40, 64]), torch.Size([16, 77, 1024])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.2.2.norm] Input: [torch.Size([1, 320, 16, 40, 64])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2.2.proj_in] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.norm1] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.attn1.to_q] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.attn1.to_k] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.attn1.to_v] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.attn1.to_out.0] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.attn1.to_out.1] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.attn1.to_out] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.attn1] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.norm2] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.attn2.to_q] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.attn2.to_k] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.attn2.to_v] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.attn2.to_out.0] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.attn2.to_out.1] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.attn2.to_out] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.attn2] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.norm3] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.ff.net.0.proj] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 2560])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.ff.net.0] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 1280])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.ff.net.1] Input: [torch.Size([2560, 16, 1280])] → Output: torch.Size([2560, 16, 1280])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.ff.net.2] Input: [torch.Size([2560, 16, 1280])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.ff.net] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0.ff] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.transformer_blocks.0] Input: [torch.Size([2560, 16, 320])] → Output: torch.Size([2560, 16, 320])
[diffusion_model.input_blocks.2.2.proj_out] Input: [torch.Size([1, 2560, 16, 320])] → Output: torch.Size([1, 2560, 16, 320])
[diffusion_model.input_blocks.2.2] Input: [torch.Size([1, 320, 16, 40, 64]), torch.Size([16, 77, 1024])] → Output: torch.Size([1, 320, 16, 40, 64])
[diffusion_model.input_blocks.2] Input: [torch.Size([16, 320, 40, 64]), torch.Size([16, 1280])] → Output: torch.Size([16, 320, 40, 64])
[diffusion_model.input_blocks.3.0.op] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 20, 32])
[diffusion_model.input_blocks.3.0] Input: [torch.Size([16, 320, 40, 64])] → Output: torch.Size([16, 320, 20, 32])
[diffusion_model.input_blocks.3] Input: [torch.Size([16, 320, 40, 64]), torch.Size([16, 1280])] → Output: torch.Size([16, 320, 20, 32])
[diffusion_model.input_blocks.4.0.in_layers.0] Input: [torch.Size([16, 320, 20, 32])] → Output: torch.Size([16, 320, 20, 32])
[diffusion_model.input_blocks.4.0.in_layers.1] Input: [torch.Size([16, 320, 20, 32])] → Output: torch.Size([16, 320, 20, 32])
[diffusion_model.input_blocks.4.0.in_layers.2] Input: [torch.Size([16, 320, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.4.0.in_layers] Input: [torch.Size([16, 320, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.4.0.emb_layers.0] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.4.0.emb_layers.1] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 640])
[diffusion_model.input_blocks.4.0.emb_layers] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 640])
[diffusion_model.input_blocks.4.0.out_layers.0] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.4.0.out_layers.1] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.4.0.out_layers.2] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.4.0.out_layers.3] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.4.0.out_layers] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.4.0.skip_connection] Input: [torch.Size([16, 320, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv1.0] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv1.1] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv1.2] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv1] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv2.0] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv2.1] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv2.2] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv2.3] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv2] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv3.0] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv3.1] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv3.2] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv3.3] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv3] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv4.0] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv4.1] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv4.2] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv4.3] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv.conv4] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0.temopral_conv] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.0] Input: [torch.Size([16, 320, 20, 32]), torch.Size([16, 1280]), <class 'int'>] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.4.1.norm] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.4.1.proj_in] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.1] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k] Input: [torch.Size([16, 77, 1024])] → Output: torch.Size([16, 77, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v] Input: [torch.Size([16, 77, 1024])] → Output: torch.Size([16, 77, 640])
[DEBUG] Height: 20, Width: 32
[diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.1] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 5120])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 2560])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.1] Input: [torch.Size([16, 640, 2560])] → Output: torch.Size([16, 640, 2560])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2] Input: [torch.Size([16, 640, 2560])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0.ff] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.transformer_blocks.0] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1.proj_out] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.4.1] Input: [torch.Size([16, 640, 20, 32]), torch.Size([16, 77, 1024])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.4.2.norm] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4.2.proj_in] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.norm1] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.attn1.to_q] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.attn1.to_k] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.attn1.to_v] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.attn1.to_out.0] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.attn1.to_out.1] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.attn1.to_out] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.attn1] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.norm2] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.attn2.to_q] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.attn2.to_k] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.attn2.to_v] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.attn2.to_out.0] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.attn2.to_out.1] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.attn2.to_out] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.attn2] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.norm3] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.ff.net.0.proj] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 5120])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.ff.net.0] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 2560])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.ff.net.1] Input: [torch.Size([640, 16, 2560])] → Output: torch.Size([640, 16, 2560])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.ff.net.2] Input: [torch.Size([640, 16, 2560])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.ff.net] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0.ff] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.transformer_blocks.0] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.4.2.proj_out] Input: [torch.Size([1, 640, 16, 640])] → Output: torch.Size([1, 640, 16, 640])
[diffusion_model.input_blocks.4.2] Input: [torch.Size([1, 640, 16, 20, 32]), torch.Size([16, 77, 1024])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.4] Input: [torch.Size([16, 320, 20, 32]), torch.Size([16, 1280])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.5.0.in_layers.0] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.5.0.in_layers.1] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.5.0.in_layers.2] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.5.0.in_layers] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.5.0.emb_layers.0] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.5.0.emb_layers.1] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 640])
[diffusion_model.input_blocks.5.0.emb_layers] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 640])
[diffusion_model.input_blocks.5.0.out_layers.0] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.5.0.out_layers.1] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.5.0.out_layers.2] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.5.0.out_layers.3] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.5.0.out_layers] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.5.0.skip_connection] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv1.0] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv1.1] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv1.2] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv1] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv2.0] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv2.1] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv2.2] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv2.3] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv2] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv3.0] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv3.1] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv3.2] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv3.3] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv3] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv4.0] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv4.1] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv4.2] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv4.3] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv.conv4] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0.temopral_conv] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.0] Input: [torch.Size([16, 640, 20, 32]), torch.Size([16, 1280]), <class 'int'>] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.5.1.norm] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.5.1.proj_in] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.1] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k] Input: [torch.Size([16, 77, 1024])] → Output: torch.Size([16, 77, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v] Input: [torch.Size([16, 77, 1024])] → Output: torch.Size([16, 77, 640])
[DEBUG] Height: 20, Width: 32
[diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.1] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 5120])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 2560])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.1] Input: [torch.Size([16, 640, 2560])] → Output: torch.Size([16, 640, 2560])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2] Input: [torch.Size([16, 640, 2560])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0.ff] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.transformer_blocks.0] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1.proj_out] Input: [torch.Size([16, 640, 640])] → Output: torch.Size([16, 640, 640])
[diffusion_model.input_blocks.5.1] Input: [torch.Size([16, 640, 20, 32]), torch.Size([16, 77, 1024])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.5.2.norm] Input: [torch.Size([1, 640, 16, 20, 32])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5.2.proj_in] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.norm1] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.attn1.to_q] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.attn1.to_k] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.attn1.to_v] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.attn1.to_out.0] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.attn1.to_out.1] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.attn1.to_out] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.attn1] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.norm2] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.attn2.to_q] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.attn2.to_k] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.attn2.to_v] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.attn2.to_out.0] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.attn2.to_out.1] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.attn2.to_out] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.attn2] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.norm3] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.ff.net.0.proj] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 5120])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.ff.net.0] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 2560])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.ff.net.1] Input: [torch.Size([640, 16, 2560])] → Output: torch.Size([640, 16, 2560])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.ff.net.2] Input: [torch.Size([640, 16, 2560])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.ff.net] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0.ff] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.transformer_blocks.0] Input: [torch.Size([640, 16, 640])] → Output: torch.Size([640, 16, 640])
[diffusion_model.input_blocks.5.2.proj_out] Input: [torch.Size([1, 640, 16, 640])] → Output: torch.Size([1, 640, 16, 640])
[diffusion_model.input_blocks.5.2] Input: [torch.Size([1, 640, 16, 20, 32]), torch.Size([16, 77, 1024])] → Output: torch.Size([1, 640, 16, 20, 32])
[diffusion_model.input_blocks.5] Input: [torch.Size([16, 640, 20, 32]), torch.Size([16, 1280])] → Output: torch.Size([16, 640, 20, 32])
[diffusion_model.input_blocks.6.0.op] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 10, 16])
[diffusion_model.input_blocks.6.0] Input: [torch.Size([16, 640, 20, 32])] → Output: torch.Size([16, 640, 10, 16])
[diffusion_model.input_blocks.6] Input: [torch.Size([16, 640, 20, 32]), torch.Size([16, 1280])] → Output: torch.Size([16, 640, 10, 16])
[diffusion_model.input_blocks.7.0.in_layers.0] Input: [torch.Size([16, 640, 10, 16])] → Output: torch.Size([16, 640, 10, 16])
[diffusion_model.input_blocks.7.0.in_layers.1] Input: [torch.Size([16, 640, 10, 16])] → Output: torch.Size([16, 640, 10, 16])
[diffusion_model.input_blocks.7.0.in_layers.2] Input: [torch.Size([16, 640, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.7.0.in_layers] Input: [torch.Size([16, 640, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.7.0.emb_layers.0] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.7.0.emb_layers.1] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.7.0.emb_layers] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.7.0.out_layers.0] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.7.0.out_layers.1] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.7.0.out_layers.2] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.7.0.out_layers.3] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.7.0.out_layers] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.7.0.skip_connection] Input: [torch.Size([16, 640, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv1.0] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv1.1] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv1.2] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv1] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv2.0] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv2.1] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv2.2] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv2.3] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv2] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv3.0] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv3.1] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv3.2] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv3.3] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv3] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv4.0] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv4.1] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv4.2] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv4.3] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv.conv4] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0.temopral_conv] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.0] Input: [torch.Size([16, 640, 10, 16]), torch.Size([16, 1280]), <class 'int'>] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.7.1.norm] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.7.1.proj_in] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.1] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k] Input: [torch.Size([16, 77, 1024])] → Output: torch.Size([16, 77, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v] Input: [torch.Size([16, 77, 1024])] → Output: torch.Size([16, 77, 1280])
[DEBUG] Height: 10, Width: 16
[diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.1] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 10240])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 5120])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.1] Input: [torch.Size([16, 160, 5120])] → Output: torch.Size([16, 160, 5120])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2] Input: [torch.Size([16, 160, 5120])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0.ff] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.transformer_blocks.0] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1.proj_out] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.7.1] Input: [torch.Size([16, 1280, 10, 16]), torch.Size([16, 77, 1024])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.7.2.norm] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7.2.proj_in] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.norm1] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.attn1.to_q] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.attn1.to_k] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.attn1.to_v] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.attn1.to_out.0] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.attn1.to_out.1] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.attn1.to_out] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.attn1] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.norm2] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.attn2.to_q] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.attn2.to_k] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.attn2.to_v] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.attn2.to_out.0] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.attn2.to_out.1] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.attn2.to_out] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.attn2] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.norm3] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.ff.net.0.proj] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 10240])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.ff.net.0] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 5120])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.ff.net.1] Input: [torch.Size([160, 16, 5120])] → Output: torch.Size([160, 16, 5120])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.ff.net.2] Input: [torch.Size([160, 16, 5120])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.ff.net] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0.ff] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.transformer_blocks.0] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.7.2.proj_out] Input: [torch.Size([1, 160, 16, 1280])] → Output: torch.Size([1, 160, 16, 1280])
[diffusion_model.input_blocks.7.2] Input: [torch.Size([1, 1280, 16, 10, 16]), torch.Size([16, 77, 1024])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.7] Input: [torch.Size([16, 640, 10, 16]), torch.Size([16, 1280])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.8.0.in_layers.0] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.8.0.in_layers.1] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.8.0.in_layers.2] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.8.0.in_layers] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.8.0.emb_layers.0] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.8.0.emb_layers.1] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.8.0.emb_layers] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.8.0.out_layers.0] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.8.0.out_layers.1] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.8.0.out_layers.2] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.8.0.out_layers.3] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.8.0.out_layers] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.8.0.skip_connection] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv1.0] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv1.1] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv1.2] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv1] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv2.0] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv2.1] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv2.2] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv2.3] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv2] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv3.0] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv3.1] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv3.2] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv3.3] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv3] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv4.0] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv4.1] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv4.2] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv4.3] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv.conv4] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0.temopral_conv] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.0] Input: [torch.Size([16, 1280, 10, 16]), torch.Size([16, 1280]), <class 'int'>] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.8.1.norm] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.8.1.proj_in] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.1] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k] Input: [torch.Size([16, 77, 1024])] → Output: torch.Size([16, 77, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v] Input: [torch.Size([16, 77, 1024])] → Output: torch.Size([16, 77, 1280])
[DEBUG] Height: 10, Width: 16
[diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.1] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 10240])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 5120])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.1] Input: [torch.Size([16, 160, 5120])] → Output: torch.Size([16, 160, 5120])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2] Input: [torch.Size([16, 160, 5120])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0.ff] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.transformer_blocks.0] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1.proj_out] Input: [torch.Size([16, 160, 1280])] → Output: torch.Size([16, 160, 1280])
[diffusion_model.input_blocks.8.1] Input: [torch.Size([16, 1280, 10, 16]), torch.Size([16, 77, 1024])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.8.2.norm] Input: [torch.Size([1, 1280, 16, 10, 16])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8.2.proj_in] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.norm1] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.attn1.to_q] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.attn1.to_k] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.attn1.to_v] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.attn1.to_out.0] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.attn1.to_out.1] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.attn1.to_out] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.attn1] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.norm2] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.attn2.to_q] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.attn2.to_k] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.attn2.to_v] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.attn2.to_out.0] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.attn2.to_out.1] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.attn2.to_out] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.attn2] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.norm3] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.ff.net.0.proj] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 10240])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.ff.net.0] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 5120])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.ff.net.1] Input: [torch.Size([160, 16, 5120])] → Output: torch.Size([160, 16, 5120])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.ff.net.2] Input: [torch.Size([160, 16, 5120])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.ff.net] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0.ff] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.transformer_blocks.0] Input: [torch.Size([160, 16, 1280])] → Output: torch.Size([160, 16, 1280])
[diffusion_model.input_blocks.8.2.proj_out] Input: [torch.Size([1, 160, 16, 1280])] → Output: torch.Size([1, 160, 16, 1280])
[diffusion_model.input_blocks.8.2] Input: [torch.Size([1, 1280, 16, 10, 16]), torch.Size([16, 77, 1024])] → Output: torch.Size([1, 1280, 16, 10, 16])
[diffusion_model.input_blocks.8] Input: [torch.Size([16, 1280, 10, 16]), torch.Size([16, 1280])] → Output: torch.Size([16, 1280, 10, 16])
[diffusion_model.input_blocks.9.0.op] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.9.0] Input: [torch.Size([16, 1280, 10, 16])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.9] Input: [torch.Size([16, 1280, 10, 16]), torch.Size([16, 1280])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.10.0.in_layers.0] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.10.0.in_layers.1] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.10.0.in_layers.2] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.10.0.in_layers] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.10.0.emb_layers.0] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.10.0.emb_layers.1] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.10.0.emb_layers] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.10.0.out_layers.0] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.10.0.out_layers.1] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.10.0.out_layers.2] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.10.0.out_layers.3] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.10.0.out_layers] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.10.0.skip_connection] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv1.0] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv1.1] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv1.2] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv1] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv2.0] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv2.1] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv2.2] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv2.3] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv2] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv3.0] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv3.1] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv3.2] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv3.3] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv3] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv4.0] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv4.1] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv4.2] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv4.3] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv.conv4] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0.temopral_conv] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.10.0] Input: [torch.Size([16, 1280, 5, 8]), torch.Size([16, 1280]), <class 'int'>] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.10] Input: [torch.Size([16, 1280, 5, 8]), torch.Size([16, 1280])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.11.0.in_layers.0] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.11.0.in_layers.1] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.11.0.in_layers.2] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.11.0.in_layers] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.11.0.emb_layers.0] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.11.0.emb_layers.1] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.11.0.emb_layers] Input: [torch.Size([16, 1280])] → Output: torch.Size([16, 1280])
[diffusion_model.input_blocks.11.0.out_layers.0] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.11.0.out_layers.1] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.11.0.out_layers.2] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.11.0.out_layers.3] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.11.0.out_layers] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.11.0.skip_connection] Input: [torch.Size([16, 1280, 5, 8])] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv1.0] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv1.1] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv1.2] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv1] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv2.0] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv2.1] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv2.2] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv2.3] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv2] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv3.0] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv3.1] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv3.2] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv3.3] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv3] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv4.0] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv4.1] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv4.2] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv4.3] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv.conv4] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0.temopral_conv] Input: [torch.Size([1, 1280, 16, 5, 8])] → Output: torch.Size([1, 1280, 16, 5, 8])
[diffusion_model.input_blocks.11.0] Input: [torch.Size([16, 1280, 5, 8]), torch.Size([16, 1280]), <class 'int'>] → Output: torch.Size([16, 1280, 5, 8])
[diffusion_model.input_blocks.11] Input: [torch.Size([16, 1280, 5, 8]), torch.Size([16, 1280])] → Output: torch.Size([16, 1280, 5, 8])
